---
title: "Implementing the WHO Long covid Definition utilizing tSPM+"
author: "Jonas HÃ¼gel & Hossein Estiri"
date: "24.04.2023"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{tSPMPlus with MLHO}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

In this vignette, we will explore how we can use the tSPM+ package to identify possibible long covid patients and their symptons. Therefore we will at first extract (long covid) candidate sequences according to the WHO definition. The WHO definition requires 2 important factors for a symptom to be long covid:
* the patient must had covid 3 months ago,
* and the symptons are onegoing for at least 2 months and can not explained by other conditions

## Defintions of candidates
We call a condition a weak candidate for a patient, if a sequence exists that starts with covid, end with that condition and has a duration >3 months.
We call a condition a candidate for a patient, if we have another sequence that starts with covid and ends with that condition, which has a duration of min(j) + 2 months

# Our Approach:
1) Identify possible weak candidates,
2) Identify possible candidates from the weak canidates
3) extract all sequences that end with a candidate
4) calculate pairwise correlation between the `startPhenx` and the tuple `(candidate, duration Bucket)`
5) exclude candidates that have sequences with a high correlation with another startPhenx and the tuple `(candidate, duration Bucket)`


```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

###Load the required packages and library
Lets start with loading the required R packages!

```{r load required packages, warning=FALSE}


if(!require(mlho)){
  require(devtools)
  devtools::install_github("hestiri/mlho")
}
if(!require(tSPMPlus)){
#  devtools::install_github("jonashuegel/tSPMPlusR", args="--recursive")
## while the code is not published install your local package version   
}
## load MLHO depenencies
if(!require(pacman)){
  install.packages("pacman")
}
pacman::p_load(data.table, devtools, backports, Hmisc, tidyr,dplyr,ggplot2,plyr,scales,readr,
               httr, DT, lubridate, tidyverse,reshape2,foreach,doParallel,caret,gbm,lubridate,praznik, epitools)

```

### Prepare the data

In this example, we are using the example data  from the [`syntheticmass covid data set](https://synthea.mitre.org/downloads) generated by [SyntheaTM](https://synthetichealth.github.io/synthea/), an open-source patient population simulation made available by [The MITRE Corporation](https://health.mitre.org/). [1] TODO cite paper We slightly modified the data set by moving all covid infections 2 years in the past to have enough data points. We are not using all available tables but limiting it to `medications, procedures, devices, allergies, immunizations and conditions`. While the observation data set would inlude useful information for an real world data set, the data there would require additional preparation steps, such as formatting it to discrete variables.




The dbmart consist of 4 rows, the patient number (`patient_num`), the phenx (`phenx`), the corresponding description for the phenx (`description`) and last but not least the date when the phenx was recorded (`start_date`).
Lets load the table and take a look at it.

```{r load data}
## load the data
load("../data/dbmart-covid19.Rdata")

## lets glance at the data frame
head(dbmart)
```

tSPM+ requires that we use numeric identifiers for the patient number as well as for the identifier of the data mart entries (phenx). Calling the `transformDbMartToNumeric` function will create numeric ids (starting by zero and counting up wards) for the patient numbers and phenx. We split the data set in cases and control. Cases are patients with covid, control without. 

```{r transform to numeric, warning=FALSE}
dbmart$phenx = as.vector(dbmart$phenx)
dbMart <- tSPMPlus::transformDbMartToNumeric(dbmart)
phenxOfInterestCode <- as.numeric(dbmart[(description=="COVID-19"),phenx])[1]
phenxOfInterest <- dbMart$phenxLookUp[(phenx==phenxOfInterestCode),num_Phenx]
caseList <- unique(dbMart$dbMart[num_Phenx==phenxOfInterest, num_pat_num])
dbmart_cases <- dbMart$dbMart[num_pat_num %in% caseList,]
dbmart_control <- dbMart$dbMart[!(num_pat_num %in% caseList),]

## dbMart contains a list of 3 Elements, the numeric dbMart, the patient ID look-up table and the phenx look-up table
head(dbMart$dbMart)
head(dbMart$phenxLookUp)
head(dbMart$patientLookUp)
```
## Determine possible Candidates

### Call tSPM+ and extract all sequences that end with a weak canidate

The `tSPM+` package provides multiple functions to extract temporal sequences. Each of these functions is calling the underlying `tSPMPlus` c++ functions with a different set of preconfigured parameters. In this example we want to extract all non-sparse transitive sequences that end with a weak candidate. Therefore, we are using the `getCandidateSequencesForPOI` function. Our `phenxOfInterest` (POI) is `Covid-19`. The `getCandidateSequencesForPOI` function returns every sequence that ends with phenX x, where the sequence starts with the `POI`(Covid-19) and has a minimum duration of 3 months. It returns a  DataFrame consisting of a numeric representation of the sequence, the duration, the endPhenx (our weak candidates), and a duration bucket.

```{r call tSPM+ and extract weak candidates}
## define function parameters

## extract the numeric representation for `COVID-19`
phenxOfInterestCode <- as.numeric(dbmart[(description=="COVID-19"),phenx])[1]
phenxOfInterest <- dbMart$phenxLookUp[(phenx==phenxOfInterestCode),num_Phenx]

outDir = "" ## set a valid path if you want to store all the plain sequences to a binary file during the creation 
outputFilePrefix = "" ## set a prefix for each patient sequence file to recognize the corresponding run easier 
storeSequencesDuringCreation = FALSE ## set to true if you want to store all the plain sequences to a file during the creation 
sparsity = 0.05
numOfThreads = detectCores() ## number of Threads used for parralelisation
temporalBucket =  c(0,1,3) ## the lower thresholds in months for the duration buckets
minDuration = 3
bitShift = 0 ## technical parameter
lengthOfPhenx = 7 ## technical parameter
sparsity = 0.05 ## sparsity value to reduce the number of created transitive sequences, default parameter

## call the function
corseq <- tSPMPlus::getCandidateSequencesForPOI(dbmart_cases, minDuration, bitShift, lengthOfPhenx,
                                                temporalBucket, phenxOfInterest, storeSequencesDuringCreation,
                                                outDir, outputFilePrefix, numOfThreads, sparsityValue = sparsity)
```

If we take a look at the `corseq` data frame, we will see that it consists of five columns. One for the patient Id, one for the sequence and for the duration (time diff between the two phenx of the sequence). The sequences are stored as numbers and but are human readable and interpretable. A sequence consists of the both numeric ids of it phenx, where the second sequence was filled with leading 0 up to seven digits. In our example the first non sparse sequence for `patient 0` is `1380000138` and consist of the both phenx with the id `138`. If we want to get the description of the corresponding phenx, we first need to look up the corresponding alphanumeric value ID in `dbMart$phenxLookUp`, before we can extract the corresponding description from the original dbmart.
We can easly see how the sequencres is constructed. For the sequence `phenx_1 = 0` -> `phenx_2 = 4`, the sequence starts with `phenx_1`. Afterwards, we append `phenx_2` filled up with so many leading `0` that we have a length of `lengthOfPhenx = 7` for `phenx_2`. Ending up with `00000004` as the numeric representaion for the sequence

```{r view sequences}
head(corseq)
```

### extract candidate sequences from the weak canidates
The `corseq` data frame contains all sequences that ends with a phenx that is weak candidate for at least one patient. For to determine the candidates we have to reduce it so that it contains only weak candidate sequences. Therefore, we extract all unique endPhenx and construct the `covid-19 -> weakCandidate` sequence for each of it.

```{r extract candidates and create candidate sequences}

## extract candidate sequences from corseq data frame
J <- data.frame(unique(corseq$endPhenx))
colnames(J) <- "endPhenx"
J$candidate_sequences <- ifelse(J$endPhenx<10,paste0(phenxOfInterest,"000000",J$endPhenx),NA)
J$candidate_sequences <- ifelse(J$endPhenx<100 & J$endPhenx>9,paste0(phenxOfInterest,"00000",J$endPhenx), J$candidate_sequences )
J$candidate_sequences <- ifelse(J$endPhenx<1000 & J$endPhenx>99,paste0(phenxOfInterest,"0000",J$endPhenx), J$candidate_sequences)

J$candidate_sequences <- as.numeric(J$candidate_sequences)
```
Now we need to shrink the `corseq` dataframe so that it only contains candidate sequences.

```{r reduce corseq so that it contains only sequences starting with covid and ending with a weak canidate}
## reduce corseq so that it contains only weak canidates
corseq_sub <- subset(corseq,corseq$sequence %in% J$candidate_sequences)
```

Now we remove all possible candidate sequences that have duration < 3 months. This results in a list of all weak candidates.
```{r apply weak candidate condition}
## since the tSPM+ functions returns all sequences that end with a possible candidate, we need to remove every sequence with a length <3 (months)
corseq_sub <- subset(corseq_sub,corseq_sub$duration >= 3)

## we might have duplicate sequences, so lets remove duplicates
corseq_sub <- dplyr::distinct(corseq_sub, .keep_all = TRUE)

```
The long covid definition requires that a condition is ongoing for 2 months. In our data this is the case if a candidate sequence occurs at least twice and, and the duration of one the later sequence is two or more months longer than the minimum duration for this sequence for the patient.
Lets start with removing every sequence for a patient that is not at least appearing twice for that patient. Afterwards we apply the sparsity screening again.
```{r remove sequences that occur only once, warning=FALSE}

corseq_sub_count <- corseq_sub %>%
  dplyr::group_by(patient_num,sequence) %>%
  dplyr::summarise(count=length((patient_num)))

## remove sequence whit only one occurrence per patient
corseq_sub_count_single <- corseq_sub_count %>%
  filter(count==1)
corseq_sub <- subset(corseq_sub,!(paste0(corseq_sub$patient_num,corseq_sub$sequence) %in%
                                                      paste0(corseq_sub_count_single$patient_num,corseq_sub_count_single$sequence)))

## redo the sparsity screen
corseq_sub_count <- corseq_sub %>%
  dplyr::group_by(sequence) %>%
  dplyr::summarise(count=length(unique(patient_num)))%>%
  filter(count > sparsity*length(unique(dbmart_cases$num_pat_num)))

corseq_sub <- subset(corseq_sub,corseq_sub$sequence %in% c(unique(corseq_sub_count$sequence)))

```
Now we can check for the 2 month duration requirement. Therefore, we calculate the minimum duration for each `covid-19 -> weakCandidate` per patient. We then remove every sequence that is not the minimum or smaller than the minimum + 2 months. Then we apply the sparsity again. The remaining sequences are sequences for candidate phenx.

``` {r  extra candidate_sequences}
###calculate the min duration for each patient and sequence
corseq_sub_min <- corseq_sub %>%
  dplyr::group_by(patient_num,sequence) %>%
  dplyr::summarise(min_duration=min((duration)))

corseq_sub <- merge(corseq_sub,corseq_sub_min,by=c("patient_num","sequence"))



corseq_sub <- subset(corseq_sub,corseq_sub$duration == corseq_sub$min_duration | corseq_sub$duration >= corseq_sub$min_duration+2)

corseq_sub_count <- corseq_sub %>%
  dplyr::group_by(patient_num,sequence) %>%
  dplyr::summarise(count=length((patient_num)))

##remove patients who only had 1 sequences to redo the sparsity screen
corseq_sub_count_single <- corseq_sub_count %>%
  filter(count==1)
corseq_sub <- subset(corseq_sub,!(paste0(corseq_sub$patient_num,corseq_sub$sequence) %in%
                                                                                          paste0(corseq_sub_count_single$patient_num,corseq_sub_count_single$sequence)))
###see if we pass the sparsity screen
corseq_sub_count <- corseq_sub %>%
dplyr::group_by(sequence) %>%
  dplyr::summarise(count=length(unique(patient_num)))%>%
  filter(count > sparsity*length(unique(dbMart$dbMart$num_pat_num)))

corseq_sub <- subset(corseq_sub,corseq_sub$sequence %in% c(unique(corseq_sub_count$sequence)))

###the remaining sequences are the ones of interest. Now extract the candidate J from them.
J <- subset(J,J$candidate_sequences  %in% c(unique(corseq_sub_count$sequence)))
```
No we can clean up, an free not required memory!
```{r clean up}
rm(corseq_sub, corseq_sub_count,corseq_sub_count_single,corseq_sub_min)
gc()
corseq_case <- subset(corseq,corseq$endPhenx %in% J$endPhenx)
rm(corseq)
gc()

```
## Compute Correlation for sequences
Now we can extract all sequences that end with our candidates, to compute the correlation between these and the candidates to remove every every candidate for which we have a sequence with a high correlation. herefore, we use the sequences from all cases and the controlls


 
```{r }
endPhenx = c(J$endPhenx)
temporalBucket =  c(0,1,3)
minDuration = 0 #technical parameter, ignore for now
bitShift = 0 #technical parameter, ignore for now
lengthOfPhenx = 7 #technical parameter
storeSequencesDuringCreation = FALSE #if true, old way -> writing out "plain" sparse sequences in patient based files, FALSE-> do in memory sparsity
dbmart_num = dbMart$dbMart

## get all the sequences that end with a candidate
corseq <- tSPMPlus::getSequencesWithEndPhenx(dbmart_num,
                                             bitShift,
                                             lengthOfPhenx,
                                             temporalBucket,
                                             endPhenx,
                                             includeCorBuckets=TRUE,
                                             minDuration,
                                             storeSequencesDuringCreation,
                                             outDir,
                                             outputFilePrefix,
                                             numOfThreads,
                                             sparsityValue=sparsity)
corseq <- dplyr::distinct(corseq, .keep_all = TRUE)

```

```{r }

#####calculate correlations
corseq <- corseq %>%
  dplyr::group_by(patient_num,sequence,endPhenx,durationBucket) %>%
  dplyr::summarise(count=length((patient_num))) 

gc()

corseq$value.var <- 1

corseq$startPhen <-substr(corseq$sequence, start = 1, stop = (nchar(corseq$sequence)-lengthOfPhenx))

corseq$startPhen_dur <- paste0(corseq$startPhen,"-",corseq$durationBucket)

dat <- data.table(corseq[c("patient_num","endPhenx","value.var","startPhen_dur")])
wide.dat.start <- dcast.data.table(dat, patient_num ~ startPhen_dur, value.var="value.var", fun=length)




end <- c(unique(J$endPhenx))
#setup parallel backend to use many processors
cores<-detectCores()
cl <- parallel::makeCluster(cores -1) #not to overload your computer
doParallel::registerDoParallel(cl)
#setup parallel backend to use many processors
# PARALELIZING THE CORRELATION CALCULATIONS
corrs <- foreach(j = 1:length(end),#
                 .combine='rbind', 
                 .multicombine=TRUE,
                 .packages = c("data.table")) %dopar% {
                   tryCatch({
                     dat.j <- data.table(corseq[corseq$endPhenx %in% end[j],c("patient_num","endPhenx","value.var")])
                     lab.j <- dcast.data.table(dat.j, patient_num ~ endPhenx, value.var="value.var", fun=length)
                     colnames(lab.j)[2] <- "label"
                     wide.j <- merge(wide.dat.start,lab.j,by="patient_num",all.x = T)
                     wide.j[is.na(wide.j)] <- 0
                     wide.j$patient_num <- NULL
                     
                     
                     out <- apply(wide.j[, -("label")], 2, cor.test, wide.j$label, method="spearman")
                     p <- data.frame(sapply(out, "[[", "p.value"))
                     p$startPhen_dur <- rownames(p)
                     rownames(p) <- NULL
                     colnames(p)[1] <- "p.value"
                     rho <- data.frame(sapply(out, "[[", "estimate"))
                     rho$startPhen_dur <- rownames(rho)
                     rownames(rho) <- NULL
                     colnames(rho)[1] <- "rho"
                     rho$startPhen_dur <- substr(rho$startPhen_dur,1,nchar(rho$startPhen_dur)-4)
                     cor.j <- merge(rho,p,by="startPhen_dur")
                     cor.j$rho.abs <- abs(cor.j$rho)
                     cor.j$endPhenx <- end[j]
                     
                     
                     rm(rho,p);gc()
                     
                     # write.csv(cor.j,file = paste0("P:/PASC/data/cors/",j,".csv"))
                     
                     
                     cor.j
                     
                   },
                   error = function(foll) {cat("ERROR :",conditionMessage(foll), "\n")})
                 }


corrs <- merge(corrs,dbMart$phenxLookUp,by.x = "endPhenx",by.y ="num_Phenx" )

```

