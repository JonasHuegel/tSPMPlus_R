---
title: "Implementing the WHO Long covid Definition utilizing tSPM+"
author: "Jonas Hügel & Hossein Estiri"
date: "May 22, 2023"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Implementing the WHO Long covid Definition utilizing tSPM+}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

In this vignette, we will explore how we can use the tSPM+ package to identify possible long covid patients and their symptoms. Therefore we will at first extract (long covid) candidate sequences according to the WHO definition. The WHO definition requires 2 important factors for a symptom to be long covid:

  * the patient must had covid 3 months ago,
  * and the symptoms are ongoing for at least 2 months and can not explained by other conditions

## Defintions of candidates
We call a condition a weak candidate for a patient, if a sequence exists that starts with covid, end with that condition and has a duration >3 months.
We call a condition a candidate for a patient, if we have another sequence that starts with covid and ends with that condition, which has a duration of min(j) + 2 months

## Our Approach:
1) Identify possible weak candidates,
2) Identify possible candidates from the weak candidates
3) extract all sequences that end with a candidate
4) calculate pairwise correlation between the `startPhenx` and the tuple `(candidate, duration Bucket)`
5) exclude candidates that have sequences with a high correlation with another startPhenx and the tuple `(candidate, duration Bucket)`


```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

### Load the required packages and library
Lets start with loading the required R packages!

```{r load required packages, warning=FALSE}


if(!require(mlho)){
  require(devtools)
  devtools::install_github("hestiri/mlho")
}
if(!require(tSPMPlus)){
#  devtools::install_github("jonashuegel/tSPMPlusR", args="--recursive")
## while the code is not published install your local package version   
}
## load MLHO depenencies
if(!require(pacman)){
  install.packages("pacman")
}
pacman::p_load(data.table, devtools, backports, Hmisc, tidyr,dplyr,ggplot2,plyr,scales,readr,
               httr, DT, lubridate, tidyverse,reshape2,foreach,doParallel,caret,gbm,lubridate,praznik, epitools)

```

### Prepare the data

In this example, we are using the example data  from the [`syntheticmass covid data set`](https://synthea.mitre.org/downloads) generated by [`SyntheaTM`](https://synthetichealth.github.io/synthea/), an open-source patient population simulation made available by [`The MITRE Corporation`](https://health.mitre.org/) [1,2]. We slightly modified the data set by moving all covid infections 2 years in the past to have enough data points, and renaming some entries. We are not using all available tables but limiting it to `medications, procedures, devices, allergies, immunizations and conditions`. While the observation data set would include useful information for an real world data set, the data there would require additional preparation steps, such as formatting it to discrete variables.





The dbmart consist of 4 rows, the patient number (`patient_num`), the phenx (`phenx`), the corresponding description for the phenx (`description`) and last but not least the date when the phenx was recorded (`start_date`).
Lets load the table and take a look at it.

```{r load data}
## load the data
load("../data/dbmart-covid19.Rda")
## lets glance at the data frame
head(dbmart)
```
```{r remove height and weight only with observations, include = FALSE}
## Lets remove Body Height & Body Weight	
dbmart <- subset(dbmart,!(dbmart$description %in% c("Body Height","Body Weight")))
```
tSPM+ requires that we use numeric identifiers for the patient number as well as for the identifier of the data mart entries (phenx). Calling the `transformDbMartToNumeric` function will create numeric ids (starting by zero and counting up wards) for the patient numbers and phenx. We split the data set in cases and control. Cases are patients with covid, control without. 

```{r transform to numeric, warning=FALSE}
dbmart$phenx = as.vector(dbmart$phenx)
dbMart <- tSPMPlus::transformDbMartToNumeric(dbmart)
phenxOfInterestCode <- as.numeric(dbmart[(description=="COVID-19"),phenx])[1]
phenxOfInterest <- dbMart$phenxLookUp[(phenx==phenxOfInterestCode),num_Phenx]
caseList <- unique(dbMart$dbMart[num_Phenx==phenxOfInterest, num_pat_num])
dbmart_cases <- dbMart$dbMart[num_pat_num %in% caseList,]
dbmart_control <- dbMart$dbMart[!(num_pat_num %in% caseList),]

## dbMart contains a list of 3 Elements, the numeric dbMart, the patient ID look-up table and the phenx look-up table
head(dbMart$dbMart)
head(dbMart$phenxLookUp)
head(dbMart$patientLookUp)
```
## Determine possible Candidates

### Call tSPM+ and extract all sequences that end with a weak canidate

The `tSPM+` package provides multiple functions to extract temporal sequences. Each of these functions is calling the underlying `tSPMPlus` c++ functions with a different set of preconfigured parameters. In this example we want to extract all non-sparse transitive sequences that end with a weak candidate. Therefore, we are using the `getCandidateSequencesForPOI` function. Our `phenxOfInterest` (POI) is `Covid-19`. The `getCandidateSequencesForPOI` function returns every sequence that ends with phenX x, where the sequence starts with the `POI`(Covid-19) and has a minimum duration of 3 months. It returns a  DataFrame consisting of a numeric representation of the sequence, the duration, the endPhenx (our weak candidates), and a duration bucket.

```{r call tSPM+ and extract weak candidates}
## define function parameters

## extract the numeric representation for `COVID-19`
phenxOfInterestCode <- as.numeric(dbmart[(description=="COVID-19"),phenx])[1]
phenxOfInterest <- dbMart$phenxLookUp[(phenx==phenxOfInterestCode),num_Phenx]

outDir = "" ## set a valid path if you want to store all the plain sequences to a binary file during the creation 
outputFilePrefix = "" ## set a prefix for each patient sequence file to recognize the corresponding run easier 
storeSequencesDuringCreation = FALSE ## set to true if you want to store all the plain sequences to a file during the creation 
sparsity = 0.05
numOfThreads = detectCores() ## number of Threads used for parralelisation
temporalBucket =  c(0,1,3) ## the lower thresholds in months for the duration buckets
minDuration = 0
bitShift = 0 ## technical parameter
lengthOfPhenx = 7 ## technical parameter
sparsity = 0.05 ## sparsity value to reduce the number of created transitive sequences, default parameter

## call the function
corseq <- tSPMPlus::getCandidateSequencesForPOI(dbmart_cases, minDuration, bitShift, lengthOfPhenx,
                                                temporalBucket, phenxOfInterest, storeSequencesDuringCreation,
                                                outDir, outputFilePrefix, numOfThreads, sparsityValue = sparsity)
```

If we take a look at the `corseq` data frame, we will see that it consists of five columns. One for the patient Id, one for the sequence and for the duration (time diff between the two phenx of the sequence). The sequences are stored as numbers and but are human readable and interpretable. A sequence consists of the both numeric ids of it phenx, where the second sequence was filled with leading 0 up to seven digits. In our example the first non sparse sequence for `patient 0` is `1380000138` and consist of the both phenx with the id `138`. If we want to get the description of the corresponding phenx, we first need to look up the corresponding alphanumeric value ID in `dbMart$phenxLookUp`, before we can extract the corresponding description from the original dbmart.
We can now  see how the sequence is constructed. For the sequence `phenx_1 = 0` -> `phenx_2 = 4`, the sequence starts with `phenx_1`. Afterwards, we append `phenx_2` filled up with so many leading `0` that we have a length of `lengthOfPhenx = 7` for `phenx_2`. Ending up with `00000004` as the numeric representaion for the sequence.

```{r view sequences}
head(corseq)
```

### extract candidate sequences from the weak canidates
The `corseq` data frame contains all sequences that ends with a phenx that is weak candidate for at least one patient. For to determine the candidates we have to reduce it so that it contains only weak candidate sequences. Therefore, we extract all unique endPhenx and construct the `covid-19 -> weakCandidate` sequence for each of it.

```{r extract candidates and create candidate sequences}

## extract candidate sequences from corseq data frame
J <- data.frame(unique(corseq$endPhenx))
colnames(J) <- "endPhenx"
J$candidate_sequences <- ifelse(J$endPhenx<10,paste0(phenxOfInterest,"000000",J$endPhenx),NA)
J$candidate_sequences <- ifelse(J$endPhenx<100 & J$endPhenx>9,paste0(phenxOfInterest,"00000",J$endPhenx), J$candidate_sequences )
J$candidate_sequences <- ifelse(J$endPhenx<1000 & J$endPhenx>99,paste0(phenxOfInterest,"0000",J$endPhenx), J$candidate_sequences)

J$candidate_sequences <- as.numeric(J$candidate_sequences)
```
Now we need to shrink the `corseq` dataframe so that it only contains candidate sequences.

```{r reduce corseq so that it contains only sequences starting with covid and ending with a weak canidate}
## reduce corseq so that it contains only weak canidates
corseq_sub <- subset(corseq,corseq$sequence %in% J$candidate_sequences)
```
Now we remove all possible candidate sequences that have duration < 3 months. This results in a list of all weak candidates.
```{r apply weak candidate condition}
## since the tSPM+ functions returns all sequences that end with a possible candidate, we need to remove every sequence with a length <3 (months)
corseq_sub <- subset(corseq_sub,corseq_sub$duration >= 3)

## we might have duplicate sequences, so lets remove duplicates
corseq_sub <- dplyr::distinct(corseq_sub, .keep_all = TRUE)

```
The long covid definition requires that a condition is ongoing for 2 months. In our data this is the case if a candidate sequence occurs at least twice and, and the duration of one the later sequence is two or more months longer than the minimum duration for this sequence for the patient.
Lets start with removing every sequence for a patient that is not at least appearing twice for that patient. Afterwards we apply the sparsity screening again.
```{r remove sequences that occur only once, warning=FALSE}

corseq_sub_count <- corseq_sub %>%
  dplyr::group_by(patient_num,sequence) %>%
  dplyr::summarise(count=length((patient_num)))

## remove sequence whit only one occurrence per patient
corseq_sub_count_single <- corseq_sub_count %>%
  filter(count==1)
corseq_sub <- subset(corseq_sub,!(paste0(corseq_sub$patient_num,corseq_sub$sequence) %in%
                                                      paste0(corseq_sub_count_single$patient_num,corseq_sub_count_single$sequence)))

## redo the sparsity screen
corseq_sub_count <- corseq_sub %>%
  dplyr::group_by(sequence) %>%
  dplyr::summarise(count=length(unique(patient_num)))%>%
  filter(count > sparsity*length(unique(dbmart_cases$num_pat_num)))

corseq_sub <- subset(corseq_sub,corseq_sub$sequence %in% c(unique(corseq_sub_count$sequence)))

```
Now we can check for the 2 month duration requirement. Therefore, we calculate the minimum duration for each `covid-19 -> weakCandidate` per patient. We then remove every sequence that is not the minimum or smaller than the minimum + 2 months. Then we apply the sparsity again. The remaining sequences are sequences for candidate phenx.

``` {r  extra candidate_sequences}
### calculate the min duration for each patient and sequence
corseq_sub_min <- corseq_sub %>%
  dplyr::group_by(patient_num,sequence) %>%
  dplyr::summarise(min_duration=min((duration)))

corseq_sub <- merge(corseq_sub,corseq_sub_min,by=c("patient_num","sequence"))

corseq_sub <- subset(corseq_sub,corseq_sub$duration == corseq_sub$min_duration | corseq_sub$duration >= corseq_sub$min_duration+2)

corseq_sub_count <- corseq_sub %>%
  dplyr::group_by(patient_num,sequence) %>%
  dplyr::summarise(count=length((patient_num)))

## remove patients who only had 1 sequences to redo the sparsity screen
corseq_sub_count_single <- corseq_sub_count %>%
  filter(count==1)
corseq_sub <- subset(corseq_sub,!(paste0(corseq_sub$patient_num,corseq_sub$sequence) %in%
                                                                                          paste0(corseq_sub_count_single$patient_num,corseq_sub_count_single$sequence)))
### see if we pass the sparsity screen
corseq_sub_count <- corseq_sub %>%
dplyr::group_by(sequence) %>%
  dplyr::summarise(count=length(unique(patient_num)))%>%
  filter(count > sparsity*length(unique(dbMart$dbMart$num_pat_num)))

corseq_sub <- subset(corseq_sub,corseq_sub$sequence %in% c(unique(corseq_sub_count$sequence)))

###the remaining sequences are the ones of interest. Now extract the candidate J from them.
J <- subset(J,J$candidate_sequences  %in% c(unique(corseq_sub_count$sequence)))
```
Now we can clean up and free not required memory!
```{r clean up}
rm(corseq_sub, corseq_sub_count,corseq_sub_count_single,corseq_sub_min)
gc()
corseq_case <- subset(corseq,corseq$endPhenx %in% J$endPhenx)
rm(corseq)
gc()

```
## Compute Correlation for sequences
The WHO definition is a definition by exclusion which means that we have to remove all candidates which we can excluded based on other existing sequences for the patient that have high correlation and significant p-value with the corresponding candidate and sequence duration.

### Extract all sequences that end with a candidate
Now we can extract all sequences that end with our candidates, to compute the correlation between these and the candidates. Herefore, we use the sequences from all cases and the controls and applying the 'getSequencesWithEndPhenx' function from the tSPM+ package.  Through the `includeCorBuckets=TRUE` parameter the function returns not only the patientId, sequence and duration, but also includes a collumn for the endPhenx and the duration bucket, which are needed for the correlation calculation.

 
```{r }
endPhenx = c(J$endPhenx)
temporalBucket =  c(0,1,3)
minDuration = 0 #technical parameter, ignore for now
bitShift = 0 #technical parameter, ignore for now
lengthOfPhenx = 7 #technical parameter
storeSequencesDuringCreation = FALSE #if true, old way -> writing out "plain" sparse sequences in patient based files, FALSE-> do in memory sparsity
dbmart_num = dbMart$dbMart

## get all the sequences that end with a candidate
corseq <- tSPMPlus::getSequencesWithEndPhenx(dbmart_num,
                                             bitShift,
                                             lengthOfPhenx,
                                             temporalBucket,
                                             endPhenx,
                                             includeCorBuckets=TRUE,
                                             minDuration,
                                             storeSequencesDuringCreation,
                                             outDir,
                                             outputFilePrefix,
                                             numOfThreads,
                                             sparsityValue=sparsity)
corseq <- dplyr::distinct(corseq, .keep_all = TRUE)

## Lets glance at the data frame
head(corseq)
```
### Calculate the correlations
#### Preparation
Now that we extracted all sequences, we can prepare the calculation of the correlations. Therefore, we summarize the sequences per patient and duration bucket. Afterwards, we merge the corresonding startPhenx and the durationBucket of the sequences for each endPhenx, before we transform 
```{r }

## Prepare to calculate correlations
corseq <- corseq %>%
  dplyr::group_by(patient_num,sequence,endPhenx,durationBucket) %>%
  dplyr::summarise(count=length((patient_num))) 

gc()

corseq$value.var <- 1

corseq$startPhen <-substr(corseq$sequence, start = 1, stop = (nchar(corseq$sequence)-lengthOfPhenx))

corseq$startPhen_dur <- paste0(corseq$startPhen,"-",corseq$durationBucket)

dat <- data.table(corseq[c("patient_num","endPhenx","value.var","startPhen_dur")])
wide.dat.start <- dcast.data.table(dat, patient_num ~ startPhen_dur, value.var="value.var", fun=length)

# list all unique endPhenx in a vector
end <- c(unique(J$endPhenx))
```
#### Calculation
Now we can iterate over the endPhenx vector to calculate all the spearmen correlations for the corresponding endPhenx in parallel.   
``` {r correlation computation}
## Correlation computation

## setup parallel back end to use many processors,  R check (cran) allows a maximum  of 2 

chk <- Sys.getenv("_R_CHECK_LIMIT_CORES_", "")

if (nzchar(chk) && chk == "TRUE") {
    # use 2 cores in CRAN/Travis/AppVeyor
    cores <- 2L
} else {
    # use all cores in devtools::test()
    cores <- parallel::detectCores() -1 #not to overload your computer
}
cl <- parallel::makeCluster(cores) 
doParallel::registerDoParallel(cl)

## PARALELIZING THE CORRELATION CALCULATIONS
corrs <- foreach(j = 1:length(end),#
                 .combine='rbind', 
                 .multicombine=TRUE,
                 .packages = c("data.table")) %dopar% {
                   tryCatch({
                     dat.j <- data.table(corseq[corseq$endPhenx %in% end[j],c("patient_num","endPhenx","value.var")])
                     lab.j <- dcast.data.table(dat.j, patient_num ~ endPhenx, value.var="value.var", fun=length)
                     colnames(lab.j)[2] <- "label"
                     wide.j <- merge(wide.dat.start,lab.j,by="patient_num",all.x = T)
                     wide.j[is.na(wide.j)] <- 0
                     wide.j$patient_num <- NULL
                     
                     out <- apply(wide.j[, -("label")], 2, cor.test, wide.j$label, method="spearman")
                     p <- data.frame(sapply(out, "[[", "p.value"))
                     p$startPhen_dur <- rownames(p)
                     rownames(p) <- NULL
                     colnames(p)[1] <- "p.value"
                     rho <- data.frame(sapply(out, "[[", "estimate"))
                     rho$startPhen_dur <- rownames(rho)
                     rownames(rho) <- NULL
                     colnames(rho)[1] <- "rho"
                     rho$startPhen_dur <- substr(rho$startPhen_dur,1,nchar(rho$startPhen_dur)-4)
                     cor.j <- merge(rho,p,by="startPhen_dur")
                     cor.j$rho.abs <- abs(cor.j$rho)
                     cor.j$endPhenx <- end[j]
                     
                     rm(rho,p);gc()
                     
                     # write.csv(cor.j,file = paste0("P:/PASC/data/cors/",j,".csv"))
                     
                     cor.j
                     
                   },
                   error = function(foll) {cat("ERROR :",conditionMessage(foll), "\n")})
                 }

corrs <- merge(corrs,dbMart$phenxLookUp,by.x = "endPhenx",by.y ="num_Phenx" )

``` 

In this step, we are extracting the significant sequences, which we use for the exclusion, after re-sequencing all sequences that end with a candidate an. Furthermore, we enrich each entry of the correlation matrix with the corresponding startPhenx and the sequence.
```{r recreate corseq matrix, warning=FALSE}
## recreate all sequences that end with a candidate

corseq <- tSPMPlus::getSequencesWithEndPhenx(dbmart_cases,
                                             bitShift,
                                             lengthOfPhenx,
                                             temporalBucket,
                                             endPhenx,
                                             includeCorBuckets=TRUE,
                                             minDuration,
                                             storeSequencesDuringCreation,
                                             outDir,
                                             outputFilePrefix,
                                             numOfThreads,
                                             sparsityValue=sparsity)
corseq <- dplyr::distinct(corseq, .keep_all = TRUE)

## store a  subset of all candidate sequences with a significant p-value
corrs_cov_J_sig <- subset(corrs,corrs$sequence >0 & corrs$p.value <=0.05)
unique(corrs_cov_J_sig$endPhenx)

## add startphenx and and sequence to the correlation matrices
corrs$startPhenx <- sub("\\-.*", "", corrs$startPhen_dur)
corrs$sequence <- ifelse (corrs$endPhenx <10,paste0(corrs$startPhenx,"000000",corrs$endPhenx),NA)
corrs$sequence <- ifelse(corrs$endPhenx <100 & corrs$endPhenx >9 ,paste0(corrs$startPhenx,"00000",corrs$endPhenx),corrs$sequence)
corrs$sequence <- ifelse(corrs$endPhenx <1000 & corrs$endPhenx >99 ,paste0(corrs$startPhenx,"0000",corrs$endPhenx),corrs$sequence)

corrs$sequence <- as.numeric(corrs$sequence)

## call the garbage collector
gc()

```

Since corseq contains again all sequences ending with a candidate, we are now analysing on a patient level if the phenx is a candidate for this patient.Therefore, for every patient, for every candidate, we remove every canidate with a min duration <3 months. Additionally, we remove every candidate that appears for the first time one year or later after the covid infection of this patient.

```{r if the min COV->J is less than 3 months, drop J for that patient}

## if the min COV->J is less than 3 months, drop J for that patient
## #calculate the min duration for each patient and sequence
corseq_sub_min <- corseq %>%
  filter(endPhenx  %in% J$endPhenx)  %>%
  dplyr::group_by(patient_num,sequence,endPhenx) %>%
  dplyr::summarise(min_duration=min((duration))) %>%
  filter(str_detect(sequence, paste0("^",phenxOfInterest))) %>% ## regexp get all sequences starting with covid  (phenxofInterest)
  filter(min_duration <3 | min_duration >12)
corseq_sub_min$pat_endPhenx <- paste0(corseq_sub_min$patient_num,corseq_sub_min$endPhenx)
exclusion1 <- c(unique(corseq_sub_min$pat_endPhenx))

corseq$pat_endPhenx <- paste0(corseq$patient_num,corseq$endPhenx)

corseq <- subset(corseq,!(corseq$pat_endPhenx %in% exclusion1))

```

### see if COVID-->J can be explained by an event prior
Now, check if we can exclude a candidate for a patient based on the fact that the patient had this candidate already in the past and the sequence candidate -> candidate has a significant high correlation.
```{r see if COVID-->J can be explained by an event prior, warning=FALSE}

## see if COVID-->J can be explained by an event prior

corrs$key_corr <- paste0(corrs$endPhenx,"--",corrs$startPhen_dur)
corseq$startPhen <-substr(corseq$sequence, start = 1, stop = (nchar(corseq$sequence)-lengthOfPhenx))
corseq$startPhen_dur <- paste0(corseq$startPhen,"-",corseq$durationBucket)
corseq$key_corr <- paste0(corseq$endPhenx,"--",corseq$startPhen_dur)


## recalculate and merge min date to corseq
corseq_sub_min <- corseq %>%
  filter(endPhenx  %in% J$endPhenx)  %>%
  dplyr::group_by(patient_num,sequence) %>%
  dplyr::summarise(min_duration=min((duration)))

corseq <- merge(corseq,corseq_sub_min,by=c("patient_num","sequence"))
corseq$delta_dur <- corseq$duration-corseq$min_duration


## if a patient does not have a second sequence of COVID->J, J has to be dropped from that patient because the 2+ months does not apply
corseq_sub_covJ <- corseq %>%
  filter(endPhenx  %in% J$endPhenx)  %>%
  filter(startPhen == phenxOfInterest)

corseq_sub_covJ_count1 <- corseq_sub_covJ %>%
dplyr::group_by(patient_num,sequence,endPhenx) %>%
  dplyr::summarise(count=length((patient_num))) %>%
  filter(count==1 & endPhenx != phenxOfInterest) %>%
  mutate(pat_endPhenx = paste0(patient_num,endPhenx))

exclusion2 <- c(unique(corseq_sub_covJ_count1$pat_endPhenx))

corseq <- subset(corseq,!(corseq$pat_endPhenx %in% exclusion2))

## if a patient has a second sequence of COVID->J, the maximum delta duration should be longer than 2, which means that the 2nd COVID->J happened 2 months or longer after the first 

corseq_sub_covJ <- corseq %>%
  filter(endPhenx  %in% J$endPhenx)  %>%
  filter(startPhen == phenxOfInterest & delta_dur !=0)

corseq_sub_covJ_dur2plus <- corseq_sub_covJ %>%
  dplyr::group_by(patient_num,sequence,endPhenx) %>%
  dplyr::summarise(max_delta_dur=max((delta_dur))) %>%
  filter(max_delta_dur < 2) %>%
  mutate(pat_endPhenx = paste0(patient_num,endPhenx))

exclusion3 <- c(unique(corseq_sub_covJ_dur2plus$pat_endPhenx))

corseq <- subset(corseq,!(corseq$pat_endPhenx %in% exclusion3))

## now incorporating correlations

exlusion_corrs <- subset(corrs,corrs$p.value <= 0.005 & corrs$rho.abs > 0.9)

### J->J sequences
# we will only remove Js when J->J with longer than 3 months is significant and also the patient has a J-->COVID sequence

JJ3 <- exlusion_corrs %>%
  filter(endPhenx == startPhenx & startPhen_dur %like% "-3" & endPhenx!= phenxOfInterest) 

JJ3$JCOV <- paste0(JJ3$startPhenx,"0000",phenxOfInterest)

JJ3$JCOV <- as.numeric(JJ3$JCOV)

for (i in 1:nrow(JJ3)){
  tryCatch({
  
print(paste0("for J ",i))
  pat.key_cor <- c(unique(subset(corseq$patient_num,corseq$key_corr == JJ3[i,"key_corr"])))
  pat.jcov <- c(unique(subset(corseq$patient_num,corseq$sequence == JJ3[i,"JCOV"])))
  
  pat.rem.j <- intersect(pat.key_cor,pat.jcov)
  corseq <- subset(corseq,!(corseq$patient_num %in% pat.rem.j & corseq$endPhenx == JJ3[i,"endPhenx"]))
rm(pat.key_cor,pat.jcov,pat.rem.j)
},
error = function(foll) {cat("ERROR :",conditionMessage(foll), "\n")})
  
  }

```
Let's take a look at the remaining candidates, after we excluded the `J->J`, we have still might be able to exclude some candidates that are explainable by other phenx. 

```{r X->J sequences, warning=FALSE}

###X->J sequences
## we will only remove j when X->J is significant and X !=J
## lets get all candidates sequences, that don't start and end with J and also don't end with Covid
XJ <- exlusion_corrs %>%
  filter(endPhenx != startPhenx & endPhenx!= phenxOfInterest) %>%
  filter(!(startPhen_dur %like% "-0"))

XJ$JCOV <- paste0(XJ$startPhenx,"0000",phenxOfInterest)

XJ$JCOV <- as.numeric(XJ$JCOV)

XJ.list <- c(unique(XJ$endPhenx))

for (i in 1:length(XJ.list)){
  tryCatch({
    
    print(paste0("for J ",i))
    key_cor.j <- c(unique(subset(XJ$key_corr,XJ$endPhenx == XJ.list[i])))
    pat.key_cor <- c(unique(subset(corseq$patient_num,corseq$key_corr %in% key_cor.j)))
    
    seq_JCOV.j <- c(unique(subset(XJ$JCOV,XJ$endPhenx == XJ.list[i])))
    pat.jcov <- c(unique(subset(corseq$patient_num,corseq$sequence %in% seq_JCOV.j)))
    
    pat.rem.j <- intersect(pat.key_cor,pat.jcov)
    
    
    corseq <- subset(corseq,!(corseq$patient_num %in% pat.key_cor & corseq$endPhenx ==XJ.list[i]))
    rm(pat.key_cor,key_cor.j)
  },
  error = function(foll) {cat("ERROR :",conditionMessage(foll), "\n")})
  
}


```
### clean up and print results
After removing any explainable candidate for each patient, we clean up and print the number of patients with long covid and store the identified phenx in a data frame. 
```{r final clean up, warning=FALSE}
## now we clean up the output to only keep COVID ->J records
corseq_output <- subset(corseq,corseq$startPhen == phenxOfInterest & corseq$endPhenx != phenxOfInterest)

## refresh the Js remaining
J_updated <- c(unique(corseq_output$endPhenx))
J$update <- ifelse(J$endPhenx %in% J_updated,1,0)
## create a cleaned version with the first qualifying J for each patient

corseq_output_0 <- subset(corseq_output,corseq_output$delta_dur==0)
corseq_output_0 <- merge(corseq_output_0,J,by="endPhenx")

## get descriptive statistics
length(unique(corseq_output_0$patient_num))

long_COVID_poi <- data.frame(table(corseq_output_0$endPhenx))
long_COVID_poi$Var1 <- as.numeric(as.character(long_COVID_poi$Var1))
## translate numeric Phenx to human readable alphanumeric
transformNumPhenxToDesc <- function(poi){
  if(grepl("\\D", poi)){
    out <- poi
  }else{
    phenxNum = dbMart$phenxLookUp[(num_Phenx == poi),phenx]
    out <- dbmart[(phenx == as.character(phenxNum)), description][1]
  }
  return (out)
}

for(i in 1:length(long_COVID_poi$Var1)){
  long_COVID_poi$Var1[i] <- transformNumPhenxToDesc(long_COVID_poi$Var1[i])
}

# print "long covid"

head(long_COVID_poi)

```




```{r call all, include = FALSE}
# call all
```


## References
[1] Jason Walonoski, Mark Kramer, Joseph Nichols, Andre Quina, Chris Moesel, Dylan Hall, Carlton Duffett, Kudakwashe Dube, Thomas Gallagher, Scott McLachlan, Synthea: An approach, method, and software mechanism for generating synthetic patients and the synthetic electronic health care record, Journal of the American Medical Informatics Association, Volume 25, Issue 3, March 2018, Pages 230–238, https://doi.org/10.1093/jamia/ocx079

[2] Walonoski J, Klaus S, Granger E, Hall D, Gregorowicz A, Neyarapally G, Watson A, Eastman J. Synthea™ Novel coronavirus (COVID-19) model and synthetic data set. Intelligence-Based Medicine. 2020 Nov;1:100007. https://doi.org/10.1016/j.ibmed.2020.100007 
